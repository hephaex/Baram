---
id: 018_0006194276
title: "“데이터만 새로 학습하면 독자 AI 인가?”…이현종 대표, 정부 심사기준 확대 주장"
category: 
publisher: 이데일리
author: 
		
			김현아(chaos@edaily.co.kr)
		
	
published_at: 2026-01-04 00:00
crawled_at: 2026-01-04 05:05:51
url: https://n.news.naver.com/mnews/article/018/0006194276
oid: 018
aid: 0006194276
content_hash: ad6aa68c035380c55438b1979d411af1f7c0af4d99d3ae4d29e9a7fe17a00ecb
---

# “데이터만 새로 학습하면 독자 AI 인가?”…이현종 대표, 정부 심사기준 확대 주장

**이데일리** | 2026-01-04 00:00 | 

---

업스테이지 ‘中 모델’ 베끼기 일단락 그후“토크나이저·데이터로더·분산·가속화 모듈 유사성 점수화 필요”“오픈소스 위에 세운 모델은 확장성 ‘제로’ 될 수 있다”[이데일리 김현아 기자]정부 예산 2000억원이 투입되는 ‘독자 AI 파운데이션 모델(업스테이지 솔라 오픈 100B)’에 대한 중국 모델 유사성 논란은 사실과 다르다는 것으로 일단락됐지만, 앞으로 정부가 ‘독자 AI 모델’을 평가할 때 심사기준을 확대해야 한다는 지적이 나왔다.정부는 1월 중 LG AI연구원, 업스테이지, 네이버클라우드, NC AI, SK텔레콤 등 독파모 후보 5개 컨소시엄 중 1개를 탈락시키고, 내년초까지 2개를 남길 예정이다.

이현종 빅스터 대표. 출처&#x3D;본인 페이스북에이전트 전문기업 빅스터의 이현종 대표는 “독자성 판단을 데이터 학습 여부로만 좁히면 안 된다”며 정부 심사 기준의 확대를 주장했다.이 대표는 4일 페이스북에 올린 글에서 “몇 일동안 논란 추이를 지켜봤고 본인도 흥분해 목소리를 높였다”며 “작년 2월 ‘AI 전문가 단톡방’에서 처음으로 ‘AI 고속도로’를 주장했던 사람”이라고 밝혔다. 국가대표 AI 모델의 개발·보급이 경제 발전에 기여해야 한다는 취지다.그는 당분간 ‘독자성’ 논쟁이 지속될 것으로 전망했다. 원칙론적 입장과 실용적 산업 적용 입장이 갈리며, 국가적 사업인 만큼 견해가 양분되는 것은 자연스럽다는 설명이다. 다만 짧은 사업기간 안에 기본 개발과 데이터 학습, 시연 발표까지 수행해야 하는 컨소시엄의 부담도 언급하며 “쉽지 않은 일”이라고 했다.이 대표의 핵심 문제 제기는 ‘독자성’ 기준을 ‘프리트레이닝(pre-training) 단계에서의 프롬 스크래치(from scratch)학습’으로만 강조하는 흐름에 있다. 그는 “정말 그것만 만족하면 되느냐”고 반문하며, 언어모델(LM)의 독자성과 고유성은 단순히 ‘새로운 데이터 학습’으로 확보되는 것이 아니라고 주장했다.특히 그는 서빙 단계(vLLM 등)뿐 아니라 LM(언어모델)개발 전반의 소스코드 검증이 필요하다고 봤다. 현재 전 세계적으로 트랜스포머(Transformer) 구조를 공통적으로 사용하는 것은 사실이지만, 그렇다고 “아키텍처가 유사해도 문제 삼으면 안 된다”거나 “아파치 라이선스 오픈소스는 출처만 표기하면 된다”는 식의 주장에는 동의하기 어렵다고 했다. 이는 김성훈 업스테이지 대표가 지난 2일 공개 검증회에서 “모델이 같아도 가중치를 랜덤하게 초기화한 뒤 처음부터 새로 학습하면 프롬 스크래치로 볼 수 있다”, “아파치 라이선스 오픈소스로 표시하면 된다” 등의 언급을 한 것과 온도 차가 난다.이현종 대표는 “시간이 짧으니 오픈소스를 벤치마킹해 1차 통과 후 남은 시간에 독창적으로 개발하자”는 접근도 현실성이 낮다고 지적했다. 기초가 남이 만든 오픈소스 위에 세워졌다면 이후 독창성 확보가 쉽지 않다는 이유에서다.이 대표는 이에 따라 정부의 ‘독자성’ 심사 기준에 포함돼야 할 항목으로 ①파인튜닝 모델 여부와 별개로 학습을 위한 소스코드 검토 ②유사 파라미터 수 오픈소스 모델과의 소스코드 동일성·유사성 비교 ③일반적인 라이브러리(예: 파이썬 문자열 처리) 제외 ④토크나이저·데이터 로더·모델 아키텍처·분산 및 가속화 모듈·매니지 로거 등의 동일성·유사성 집중 검토 ⑤각 항목별 점수 및 총계 산출 등을 제시했다.그는 “학습 모듈 소스코드, 아키텍처, 학습데이터, wandb 등을 상세히 구분해 통합적으로 살펴봐야 한다”며 “정부가 제공한 새로운 학습데이터로 프롬 스크래치 했다고 해서 독자적이라고 해서는 안 된다”고 강조했다. 이는 남이 만든 소스코드 기반에 유사한 구현과 모듈 조합을 사용했다면 “학습 데이터만 다를 뿐 독자적이지 않다”는 주장이다. 그는 이런 방식으로 만들어진 모델은 확장 가능성이 ‘제로’가 될 수 있다”고도 했다.

---

*Crawled at: 2026-01-04 05:05:51*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/018/0006194276)*
