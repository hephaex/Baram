---
id: 001_0015821382
title: "&#x27;독자 AI&#x27; 모델 1차 경연…5개 정예팀 모델 성능 눈길(종합)"
category: 
publisher: 연합뉴스
author: 
		
			오지은(built@yna.co.kr)
		
	
published_at: 2025-12-30 00:00
crawled_at: 2025-12-30 08:23:36
url: https://n.news.naver.com/mnews/article/001/0015821382
oid: 001
aid: 0015821382
content_hash: 8ae3444504fd13c2a52a557c5a4e88586218f4e61dc13cd6f250adb98ab9e7dd
---

# &#x27;독자 AI&#x27; 모델 1차 경연…5개 정예팀 모델 성능 눈길(종합)

**연합뉴스** | 2025-12-30 00:00 | 

---

너도나도 거대 파라미터·멀티모달…&quot;AI 3강 이끌겠다&quot;(서울&#x3D;연합뉴스) 오지은 기자 &#x3D; 과학기술정보통신부는 30일 독자 AI 파운데이션 모델 프로젝트 1차 발표회를 열었다. 이날 행사에는 SKT, LG AI연구원, 네이버클라우드, 업스테이지, NC AI 등 정예팀 5곳이 참여했다. 배경훈 부총리 겸 과기정통부 장관은 &quot;AI 모델 개발에 매진한 정예팀 모두가 승자&quot;라며 &quot;이번 도전이 대한민국을 AI 강국으로 도약시키고 경제 사회 전반의 AI 대전환을 완성하는 결정적 동력이 될 것이다&quot;라고 말했다. 발표회에서는 5개 정예팀의 AI 모델의 1차 결과물이 공개됐다. 네이버클라우드 &#x27;옴니모달 AI 모델&#x27; 선보여

네이버클라우드는 학습 단계부터 텍스트, 이미지, 음성을 동시에 이해하고 이를 생성하는 옴니모달 AI 모델을 공개했다. 네이버클라우드는 옴니모달 구조를 적용한 파운데이션 모델인 네이티브 옴니모델과 기존 추론형 AI에 시각, 음성, 도구 활용 역량을 더한 고성능 추론모델을 각각 오픈소스로 공개한다고 밝혔다. 이날 성낙호 하이퍼스케일 AI 총괄은 &quot;LLM은 책만 읽고 공부한 두뇌 같은 존재지만 옴니모달은 뛰어난 두뇌에 손과 발을 달아 보고 듣고 만지면서 입체적이고 통합적으로 학습하는 모델이다&quot;라고 설명했다. 네이버클라우드는 옴니모델의 잠재력을 극대화하기 위해 기존 인터넷 문서나 이미지 중심의 학습을 넘어 현실 세계의 맥락을 담은 데이터 확보에 집중한다는 전략이다. 추론모델의 경우 자체 추론형 AI에서 시각 이해, 음성 대화, 도구 활용 능력을 결합해 복합적인 입력과 요청을 이해한다. 해당 모델은 글로벌 AI 평가 기관 아티피셜 애널러시스가 산출한 지수 기준에서도 글로벌 AI 모델과 유사한 성능 범위에 위치한 것으로 나타났다. 또 해당 모델로 올해 대학수학능력시험 문제를 풀이한 결과 국어, 수학, 한국사 등 주요 과목에서도 1등급에 해당하는 성적을 받았다. 성 총괄은 &quot;실용성 고도화로 2027년까지 하이퍼스케일 옴니모델로 스케일업하고 물리적 세계를 이해하는 월드 모델로 나아갈 예정이다&quot;라고 강조했다.

국방·제조·패션 AI 만든다…NC AI, 배키로 도전장 NC AI는 제조, 국방, 패션 등 산업의 AI 전환을 위한 AI 파운데이션 모델 VAETKI(배키)를 공개했다. 이연수 NC AI 대표는 &quot;배키는 초거대모델부터 경량화모델, VLM까지 현장 특성에 맞춘 멀티 스케일, 멀티 모달, 멀티 모달리티를 지원한다&quot;라며 &quot;다양한 산업 데이터를 수용하고 생성하며 각 산업군에 최적화된 특화 모델을 완성하도록 지원한다&quot;라고 말했다. NC AI는 AI 모델 바로크에 3차원(3D) 생성 기술이 결합된 바로크 3D를 활용해 전 산업군에 최적화된 버티컬 AI 설루션을 제공한다는 계획이다. 이날 NC AI는 28개 산업 현장에서 진행 중인 프로젝트도 발표했다. NC AI는 스마트팩토리 전환을 위한 프로젝트를 진행하고 있고, 현대오토에버와 산업 AX를 위한 기술 협력을 수행하고 있다. 아울러 NC AI는 포스코, 롯데와 함께 물류, 유통 분야에서 AX 프로젝트는 진행 중이고, 문화 콘텐츠 영역에서도 신규 IP 지원 등 위한 프로젝트를 이어가고 있다. 이 대표는 &quot;NC AI는 1차로 100B(1천억개)급 파운데이션 모델의 틀을 마련했다&quot;라며 &quot;2차에서 200B, 3차에서 300B급으로 글로벌 모델급 성능을 달성하려고 한다&quot;라고 강조했다.

정예팀 유일 스타트업 업스테이지, &#x27;솔라 오픈&#x27; 공개 업스테이지는 이날 독자 파운데이션 모델 솔라 오픈 100B를 선보였다. 이날 발표에 나선 김성훈 업스테이지 대표는 &quot;이 모델은 한국어가 굉장히 강하다&quot;라고 강조했다. 업스테이지는 파운데이션 모델을 공개하면서 &#x27;스트로베리&#x27; 사례를 들었다. &#x27;Strawberry&#x27;라는 단어를 AI 모델에 입력하면 일반적으로 알파벳 &#x27;r&#x27;의 개수를 세지 못하는데 솔라 모델은 이를 정확하게 계산한다는 것이다. 김 대표는 또 솔라의 강점으로 &#x27;마음을 읽는다는 점&#x27;을 꼽았다. &#x27;어머니가 짜장면을 싫어하는 이유&#x27;를 검색하면 솔라는 한국의 정서를 반영해 자세하게 답변하지만 글로벌 모델은 이를 담아내지 못한다는 게 김 대표의 설명이다. 김 대표는 &quot;업스테이지는 100B에 멈추지 않고 200B, 300B 모델을 만들겠다&quot;라며 &quot;더 나아가 멀티모달 모델도 계속 만들겠다&quot;라고 말했다.

SKT, 500B 초거대 AI 모델 &#x27;A.X K1&#x27; 출사표 이날 SK텔레콤은 500B 규모 초거대 AI 모델 &#x27;A.X K1&#x27;(에이닷엑스 케이원)을 공개했다. SK텔레콤은 모델 크기가 성능과 비례하는 AI 분야에서 한국이 AI 3강에 진출하려면 500B 규모의 AI 모델이 필수적이라고 역설했다. 정석근 SKT AI CIC장은 &quot;파라미터는 뇌의 시냅스와 비슷하다&quot;라며 &quot;시냅스가 많을수록 고차원적인 사고가 가능하듯 파라미터가 많을수록 AI가 더 똑똑하고 복잡한 추론을 할 수 있다&quot;라고 말했다. 정 CIC장은 또 &quot;에이닷엑스 케이원은 한국어와 한국의 산업 환경을 집중적으로 학습해서 한국 기업의 실무 현장에서 최적화된 성능을 제공한다&quot;라고 설명했다. SK텔레콤에 따르면 에이닷엑스 케이원은 사용자의 지시를 따르는 부문, 한국어 시험 문제 풀이 부문에서 딥시크에 비해 각각 148%, 110% 우수한 것으로 평가됐다. SK텔레콤은 모두의 AI를 목표로 기업과 소비자간 거래(B2C)와 기업간거래(B2B)를 아우르는 AI 확산 역량도 강조했다. SK텔레콤은 SK하이닉스, SK이노베이션, SK AX 등 관계사와 협업으로 한국의 AI 전환에 이바지하겠다고 전했다.

LG AI 연구원, &#x27;K-엑사원&#x27;으러 AI 3강 노린다 LG AI 연구원은 독자 AI 파운데이션 모델로 &#x27;K-엑사원&#x27; 성능을 발표했다. K-엑사원은 매개변수 236B 구모 모델로, 개발 착수 5개월 만에 글로벌 빅테크 최신 오픈 웨이트 모델과 경쟁할 수 있는 수준에 도달했다. LG AI연구원은 기존 엑사원 4.0 대비 효율성을 높이면서도 메모리 요구량과 연산량을 줄여 성능과 경제성을 동시에 확보했다고 설명했다. 특히 전문가 혼합 모델 구조(MoE)에 하이브리드 어텐션 기술을 더해 메모리 및 연산 부담을 70% 줄이고, 고가의 최신 인프라가 아닌 A100급 그래픽처리장치(GPU) 환경에서 구동할 수 있도록 했다. LG AI연구원은 향후 조 단위 파라미터 규모 글로벌 최상위 모델과 경쟁할 수 있도록 성능을 고도화한다는 계획이다. LG AI연구원은 글로벌 프론티어 AI 모델을 뛰어넘는 경쟁력을 확보해 한국을 AI 3강으로 이끌겠다는 포부를 밝혔다. 과기정통부는 1월 중 정예팀을 대상으로 1차 단계평가를 진행하고 정예팀의 성과와 향후 계획을 점검해 결과를 발표할 방침이다. built@yna.co.kr

---

*Crawled at: 2025-12-30 08:23:36*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/001/0015821382)*
