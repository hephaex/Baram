---
id: 092_0002404564
title: "&quot;사진 하나로 속옷 차림 생성&quot;…그록, 성적 이미지 논란 확산"
category: 
publisher: 지디넷코리아
author: 
		
			김미정 기자(notyetkim@zdnet.co.kr)
		
	
published_at: 2026-01-04 00:00
crawled_at: 2026-01-04 05:06:43
url: https://n.news.naver.com/mnews/article/092/0002404564
oid: 092
aid: 0002404564
content_hash: 30d7771d16259fe3e42f71a0180f283e16c21b6d582298f2ba026eb359807798
---

# &quot;사진 하나로 속옷 차림 생성&quot;…그록, 성적 이미지 논란 확산

**지디넷코리아** | 2026-01-04 00:00 | 

---

젊은 여성·유명 정치인 등 성적 대상화…프랑스·인도 정부, 규제 대응 나서일론 머스크 인공지능(AI) 챗봇 &#x27;그록AI&#x27;가 실제 인물 사진을 성적으로 왜곡한 이미지를 대량 생성하면서 플랫폼 운영 책임과 AI 안전성 문제가 수면 위로 떠올랐다.4일 테크크런치 등 외신에 따르면 소셜미디어 엑스(X)에 내장된 AI 챗봇 그록이 사용자 요청에 따라 여성 사진 속 옷을 제거하거나 속옷 복장으로 바꾼 이미지를 생성한 것으로 드러났다. 일부 사례에서는 미성년자로 보이는 인물이 성적으로 대상화된 이미지도 만들어진 것으로 확인됐다.사용자가 사진을 올린 뒤 &quot;이 인물 옷차림을 비키니로 바꿔&quot; 같은 문구만 입력하면, AI가 이미지를 바로 수정하는 식으로 작동했다. 일각에선 그록이 기존 성적 합성 이미지 제작보다 훨씬 낮은 진입 장벽을 만들었다는 평가까지 나오고 있다.

그록AI&#x27;가 실제 인물 사진을 성적으로 왜곡한 이미지를 대량 생성했다. (사진&#x3D;그록3 라이브 시연 캡처)외신은 성적 대상화 이미지 생성 횟수도 증가하고 있다고 밝혔다. 실제 로이터가 10분간 공개 요청을 집계한 결과 그록으로 사진 속 인물을 비키니 차림으로 바꿔 달라는 명령이 102건인 것으로 확인됐다. 대상 인물 중 다수는 젊은 여성이었고 일부 남성 유명인 정치인, 동물도 포함됐다.이같은 AI 기반 성적 이미지 확산은 국제적 이슈로 확산하고 있다. 프랑스 정부는 성적이고 성차별적인 콘텐츠가 명백히 불법이라며 X를 검찰과 규제 당국에 신고했다. 인도 IT부처도 그록 음란 콘텐츠 생성과 유통을 막지 못했다고 지적했다.전문가들도 이번 사태가 예견된 결과라고 보고 있다. 지난해 각국 시민사회와 아동 보호 단체들은 그록 챗봇 이미지 생성 기술이 딥페이크로 악용될 가능성을 경고하는 서한을 엑스 측에 전달한 바 있다.타일러 존스턴 마이다스프로젝트 사무총장은 &quot;그록은 AI를 통해 이미지 생성을 무기화하고 있다&quot;고 지적했다. 대니 핀터 미국 국립성착취방지센터 최고법률책임자는 &quot;이번 사태는 전적으로 예측 가능했고 피할 수 없는 참사&quot;라고 밝혔다.

---

*Crawled at: 2026-01-04 05:06:43*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/092/0002404564)*
