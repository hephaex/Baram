---
id: 032_0003417839
title: "오픈AI가 ‘AI의 위험을 걱정할 사람’을 찾고 있다"
category: 
publisher: 경향신문
author: 
		
			노도현 기자 hyunee@kyunghyang.com
		
	
published_at: 2025-12-28 00:00
crawled_at: 2025-12-28 04:31:54
url: https://n.news.naver.com/mnews/article/032/0003417839
oid: 032
aid: 0003417839
content_hash: 0bd5e368203d801037af9a246a3029ab684c6baa53bb440df9a98f92815fb7bf
---

# 오픈AI가 ‘AI의 위험을 걱정할 사람’을 찾고 있다

**경향신문** | 2025-12-28 00:00 | 

---

오픈AI가 정신건강, 사이버 보안 등 인공지능(AI)의 위험성에 대비한 안전 체계를 이끌 책임자 채용에 나섰다. AI로 인한 위험이 빠르게 현실화되고 있다는 판단이 반영된 것으로 보인다.샘 올트먼 오픈AI 최고경영자(CEO)는 27일(현지시간) 엑스에 “모델들은 빠르게 발전해 많은 일을 해낼 수 있지만 동시에 현실적인 도전 과제도 드러내기 시작했다”며 ‘대비 총괄(Head of Preparedness)’을 구한다고 알렸다.오픈AI 홈페이지에 올라온 채용 공고를 보면 대비 총괄은 오픈AI의 ‘대비 프레임워크’에 대한 기술 전략 수립과 실행을 총괄하게 된다. 대비 프레임워크는 AI 기술이 고도화되면서 나타날 수 있는 위험을 미리 파악하고 대비하기 위한 체계를 말한다.올트먼 CEO는 “모델이 정신건강에 미칠 수 있는 잠재적 영향은 올해 그 전조를 볼 수 있었다”며 “이제 모델들은 컴퓨터 보안 분야에서 매우 뛰어난 수준에 이르러 중대한 취약점을 찾아내기 시작했다”고 했다.이 같은 발언은 챗GPT를 둘러싼 ‘정신건강 악화’ 논란과 맞닿아 있다. 지난 8월 미국 캘리포니아에서 10대 소년의 유족이 챗GPT가 아들의 자살을 도왔다며 소송을 제기한 이후 유사한 소송이 잇따랐다. 이달에는 챗GPT가 이용자의 망상을 부추겨 살인을 유도했다는 이유로 오픈AI가 또다시 피소됐다. 이에 오픈AI는 챗GPT에 청소년 보호자 관리 기능을 도입하고 민감한 대화에서의 응답 방식을 개선하는 등 대응에 나섰다.하지만 챗GPT를 비롯한 AI 챗봇이 정신건강 관련 질문에 적절하게 답변하지 못하고 있다는 지적은 여전하다. 지난달 비영리단체 커먼센스미디어와 스탠포드대 연구진이 발표한 보고서에 따르면 AI 챗봇들은 자살이나 자해 관련 대응은 개선했지만 불안·우울증·섭식장애·강박장애 등에 대한 경고 신호는 제대로 감지하지 못하는 것으로 나타났다. 위험 신호를 분명하게 드러낸 짧은 대화에는 비교적 잘 대응한 반면 길고 복잡한 대화에선 부적절한 답변을 내놓는 경우가 많았다.그간 오픈AI는 수익성에 집중하느라 안전을 등한시하는 것 아니냐는 비판을 받아 왔다. 기존에도 AI 안전 조직과 대비 총괄직을 두고 있었지만, 지난해 7월 대비 총괄이던 인물에게 다른 업무를 맡기면서 ‘안전 후퇴’ 우려가 커진 바 있다.이번 채용 공고에서 오픈AI는 연봉 55만5000달러(약 8억원)와 지분 보상을 제시했다. 올트먼 CEO는 “이 일은 상당히 스트레스가 클 것”이라며 “합류하자마자 곧바로 현장에 투입된다”고 말했다.

---

*Crawled at: 2025-12-28 04:31:54*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/032/0003417839)*
