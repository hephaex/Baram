---
id: 119_0003042504
title: "&#x27;소버린 AI&#x27; 프로젝트 베일 벗는다…정예 5팀 성과 경쟁 돌입"
category: 
publisher: 데일리안
author: 
		
			조인영 기자 (ciy8100@dailian.co.kr)
		
	
published_at: 2025-12-30 00:00
crawled_at: 2025-12-30 00:09:00
url: https://n.news.naver.com/mnews/article/119/0003042504
oid: 119
aid: 0003042504
content_hash: 94bc342c1224228e4c358c12c98b28cf00eabc5cda4db996678c4dfd89d09b16
---

# &#x27;소버린 AI&#x27; 프로젝트 베일 벗는다…정예 5팀 성과 경쟁 돌입

**데일리안** | 2025-12-30 00:00 | 

---

SKT 500B 초거대 AI·네이버 옴니모달·LG 엑사원 3.0 등 차별화 모델 경쟁NC 바르코·업스테이지 솔라, 산업 특화·효율적 성능 AI 선봬

[데일리안 &#x3D; 조인영 기자] 대한민국 AI 주권 확보를 위한 &#x27;독자 AI 파운데이션 모델 프로젝트&#x27;가 30일 베일을 벗는다.과학기술정보통신부는 이날 서울 코엑스에서 &#x27;독자 AI 파운데이션 모델 프로젝트 1차 발표회&#x27;를 열고 참여사 5팀의 모델 성과를 점검한다.5개 정예팀은 SK텔레콤·네이버클라우드·LG AI연구원·업스테이지·NC AI다.SKT 정예팀은 국내 최초 매개변수(파라미터) 500B(5000억개) 규모의 초거대 AI 모델 &#x27;A.X K1&#x27;을 공개한다.파라미터는 AI 모델이 추론 과정에서 조정하는 매개변수로, 파라미터가 많을수록 일반적으로 보다 정교한 연산이 가능해지지만 그만큼 비용이 늘어나는 특성이 있다.A.X K1은 총 5190억개의 매개변수로 구성되며, 사용자 요청에 의해 추론 작업을 할 때에는 약 330억개의 매개변수가 활성화되는 구조다. 초거대 규모로 학습을 하되, 필요한 경우에는 최대한 가벼운 사양으로 동작할 수 있도록 했다.SKT 정예팀은 A.X K1이 다양한 소형·특화 모델들에게 지식을 전수하도록 연구를 확장, 국민의 일상과 산업 전반에 활용할 계획이다.네이버클라우드는 ‘하이퍼클로바X 시드 8B 옴니’와 ‘하이퍼클로바X 시드 32B 싱크’를 선보인다.&#x27;하이퍼클로바 X 시드 8B 옴니&#x27;는 텍스트·이미지·오디오 등 서로 다른 형태의 데이터를 단일 모델에서 처음부터 함께 학습하는 네이티브 옴니모달 구조를 적용했다.옴니모달 AI는 정보의 형태가 달라지더라도 하나의 의미 공간에서 맥락을 통합적으로 이해할 수 있어, 말과 글, 시각·음성 정보가 복합적으로 오가는 현실 환경에서 활용도가 높은 차세대 AI 기술로 주목받고 있다.&#x27;하이퍼클로바X 시드 32B 싱크&#x27;는 인간의 사고 과정을 모방해 성능을 높인 최신 추론형 모델이다. 이 모델은 올해 대학수학능력시험 문제를 풀어 국어·수학·영어·한국사 등 주요 과목에서 일부 만점을 포함해 모두 1등급을 받았다.네이버클라우드는 향후 차별화된 데이터를 본격적으로 학습시키며 단계적인 스케일업에 나설 계획이다.

LG AI연구원은 글로벌 최고 수준의 프런티어 AI 개발을 목표로 내걸었다. 최근 오픈소스로 공개하며 성능을 입증한 &#x27;엑사원 3.0(EXAONE 3.0)&#x27;을 선보일 것으로 예상된다. 엑사원 모델이 범용성에 산업 분야 특화 전문성을 더한 고성능 AI 모델인 장점을 내세울 전망이다.NC AI는 1차 단계에서 1000억개 파라미터 규모의 모델을 예고했다. 자체 모델 &#x27;바르코(VARCO)&#x27;를 통해 창의적 콘텐츠 생성과 한국어 처리에 특화된 기술력을 선보일 것으로 보인다.NC AI는 게임 자산을 활용한 3차원(3D)과 애니메이션 분야 AI의 강점을 내세우며 제조, 유통, 미디어 등 산업 특화 AI로 분야 확대를 노리고 있다.업스테이지는 약 1026억 파라미터로 구성된 &#x27;솔라(Solar) 오픈 100B&#x27;를 먼저 선보일 전망이다. 솔라는 상대적으로 적은 매개변수로도 거대 언어 모델(LLM)에 버금가는 성능을 내는 것으로 알려졌다. 이후 반기마다 200B(2000억개)·300B(3000억개)로 파라미터를 확장한다.과기정통부는 1차 평가를 내년 1월 15일까지 진행할 예정이다. 여기서 최하위 1개팀이 탈락하게 된다. 이후 6개월마다 최종 1∼2팀이 남을 때까지 경쟁을 이어간다.지원 대상으로 선정되는 정예팀은 AI 모델 고도화에 필요한 그래픽처리장치(GPU) 등 컴퓨팅 자원과 데이터 구축·가공 비용 연간 30억∼50억원, 해외 우수 연구자 인건비, 연구비 연간 20억원 등을 받게 된다.다만 과기정통부는 탈락한 컨소시엄에 대해서도 각 팀의 특장점을 살릴 수 있는 별도의 기회 부여를 검토하고 있다.

---

*Crawled at: 2025-12-30 00:09:00*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/119/0003042504)*
