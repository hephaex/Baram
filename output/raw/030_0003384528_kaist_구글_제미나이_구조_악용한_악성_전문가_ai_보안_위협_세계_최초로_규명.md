---
id: 030_0003384528
title: "KAIST, 구글 제미나이 구조 악용한 &#x27;악성 전문가 AI&#x27; 보안 위협 세계 최초로 규명"
category: 
publisher: 전자신문
author: 
		
			김영준 kyj85@etnews.com
		
	
published_at: 2025-12-28 00:00
crawled_at: 2025-12-28 03:02:15
url: https://n.news.naver.com/mnews/article/030/0003384528
oid: 030
aid: 0003384528
content_hash: 44b4faab11defb06d79bef08e80a03cfbf7fb23b83cfec431630724b52dc83a1
---

# KAIST, 구글 제미나이 구조 악용한 &#x27;악성 전문가 AI&#x27; 보안 위협 세계 최초로 규명

**전자신문** | 2025-12-28 00:00 | 

---

구글 제미나이(Gemini) 등 대부분 상용 거대언어모델(LLM)은 효율성을 높이기 위해 여러 개 &#x27;작은 AI 모델(전문가 AI)&#x27;을 상황에 따라 선택해 사용하는 전문가 혼합(Mixture-of-Experts, MoE) 구조를 활용하고 있다. 그러나 이 구조가 오히려 새로운 보안 위협이 될 수 있다는 사실이 한국과학기술원(KAIST·총장 이광형) 연구진에 의해 세계 최초로 밝혀졌다.KAIST는 신승원 전기 및 전자공학부 교수와 손수엘 전산학부 교수 공동연구팀이 전문가 혼합 구조를 악용해 LLM 안전성을 심각하게 훼손할 수 있는 공격 기법을 세계 최초로 규명하고, 해당 연구로 정보보안 분야 최고 권위 국제 학회인 ACSAC 2025에서 최우수논문상을 수상했다고 26일 밝혔다.

ACSAC는 정보보안 분야에서 가장 영향력 있는 국제 학술대회 중 하나로, 올해 전체 논문 가운데 단 2편만이 최우수논문으로 선정됐다. 국내 연구진이 인공지능(AI) 보안 분야에서 이 같은 성과를 거둔 것은 매우 이례적이다.연구팀은 이번 연구에서 전문가 혼합 구조의 근본적인 보안 취약성을 체계적으로 분석했다. 특히 공격자가 상용 LLM 내부 구조에 직접 접근하지 않더라도, 악의적으로 조작된 &#x27;전문가 모델&#x27; 하나만 오픈소스로 유통될 경우, 이를 활용한 전체 LLM이 위험한 응답을 생성하도록 유도될 수 있음을 입증했다.쉽게 말해, 정상적인 AI 전문가들 사이에 단 하나의 &#x27;악성 전문가&#x27;만 섞여 있어도, 특정 상황에서 그 전문가가 반복적으로 선택되며 전체 AI의 안전성이 무너질 수 있다는 것이다. 이 과정에서도 모델의 성능 저하는 거의 나타나지 않아, 문제를 사전에 발견하기 어렵다는 점이 특히 위험한 요소로 지적됐다.실험 결과, 연구팀이 제안한 공격 기법은 유해 응답 발생률을 기존 0%에서 최대 80%까지 증가시킬 수 있었으며, 다수의 전문가 중 단 하나만 감염돼도 전체 모델의 안전성이 크게 저하됨을 확인했다.

이번 연구는 전 세계적으로 확산되고 있는 오픈소스 기반 LLM 개발 환경에서 발생할 수 있는 새로운 보안 위협을 최초로 제시했다는 점에서 큰 의미를 갖는다. 동시에, 앞으로 AI 모델 개발 과정에서 성능뿐 아니라 &#x27;전문가 모델의 출처와 안전성 검증&#x27;이 필수적임을 시사한다.신승원·손수엘 교수는 “효율성을 위해 빠르게 확산 중인 전문가 혼합 구조가 새로운 보안 위협이 될 수 있음을 이번 연구를 통해 실증적으로 확인했다”며, “이번 수상은 AI 보안의 중요성을 국제적으로 인정받은 의미 있는 성과”라고 말했다.이번 연구에는 KAIST 전기 및 전자공학부 김재한·송민규 박사과정, 나승호 박사 (현 삼성전자), KAIST 전기 및전 자공학부 신승원 교수, KAIST 전산학부 손수엘 교수가 참여했으며, 연구 결과는 2025년 12월 12일 미국 하와이에서 열린 ACSAC에서 발표됐다.한편 이 연구는 과학기술정보통신부의 한국인터넷진흥원(KISA) 및 정보통신기획평가원(IITP)의 지원을 받았다.

---

*Crawled at: 2025-12-28 03:02:15*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/030/0003384528)*
