---
id: 421_0008683201
title: "치열한 글로벌 AI칩 경쟁…한국은 저전력·저비용 NPU로 승부수"
category: 
publisher: 뉴스1
author: 
		
			나연준 기자 (yjra@news1.kr)
		
	
published_at: 2025-12-29 00:00
crawled_at: 2025-12-28 21:46:56
url: https://n.news.naver.com/mnews/article/421/0008683201
oid: 421
aid: 0008683201
content_hash: 180bd72c01a7b23f11eeca121753a61991909ec4fff3ef7f8fb3704b7b085363
---

# 치열한 글로벌 AI칩 경쟁…한국은 저전력·저비용 NPU로 승부수

**뉴스1** | 2025-12-29 00:00 | 

---

GPU 주도 생태계 속 구글 TPU 등 추론 중심 시장 재편한국 NPU 고도화 집중…피지컬AI 특화 기술력 확보

(서울&#x3D;뉴스1) 나연준 기자 &#x3D; 글로벌 인공지능(AI) 산업의 주도권을 둘러싼 AI 반도체 경쟁이 뜨겁게 펼쳐지고 있다. 엔비디아가 그래픽처리장치(GPU)를 앞세워 AI칩 생태계를 장악한 가운데 구글은 자체 개발한 텐서처리장치(TPU)로 반격에 나섰다. 한국은 저전력·고효율 신경망처리장치(NPU)를 고도화해 경쟁력 강화에 나선다는 전략이다.29일 업계에 따르면 엔비디아는 최근 AI 추론칩 설계전문 스타트업 그록(Groq)과 200억 달러(약 29조 원) 규모의 초고속 추론기술 라이선스 계약을 맺었다. 글로벌 반독점 규제를 우회하려고 기술 라이선스 계약을 맺었지만 사실상 기업인수에 가까운 전략적 파트너십이라는 분석이다.그록은 AI 추론칩 설계가 강점인 기업으로 구글의 TPU 개발자 중 한 명인 조나단 로스가 창업했다. 그록이 만든 AI칩 LPU(Language Processing Unit·언어처리장치)는 대형언어모델(LLM)을 GPU보다 10배 빠르지만 전략은 10분의 1만 사용해 구동할 수 있는 것으로 알려졌다.엔비디아는 그록의 LPU 기술을 흡수해 추론 부문 경쟁력을 강화할 것으로 보인다. TPU를 앞세운 구글 등의 추격이 거세지는 상황에서 경쟁사와의 격차를 유지하기 위한 행보로 풀이된다. GPU는 추론 영역에서는 전력 효율, 비용 측면에서 TPU보다 불리하다는 평가를 받고 있다.구글은 지난 11월 자체 개발한 TPU를 활용해 개발한 &#x27;제미나이(Gemini) 3&#x27;를 출시했다. 제미나이3는 각종 벤치마크에서 챗GPT 5.1을 압도하며 GPU 중심 생태계에 충격을 줬고, 이에 엔비디아 독점 체제가 흔들리는 것 아니냐는 전망까지 나왔다.제미나이3는 구글의 7세대 TPU &#x27;아이언우드&#x27;로 추론 성능을 높였다. GPU가 범용성이 강점이라면 TPU는 AI 연산에 특화된 칩이다. 특정 추론 작업에서는 GPU 대비 약 35%의 비용을 절감할 수 있는 것으로 알려졌다.AI칩 확보는 한국의 AI 경쟁력과도 직결될 전망이다. 엔비디아와 대규모 GPU 공급 계약을 체결하기도 했지만 AI 서비스의 사회 전반 확산을 위해서는 추론에 특화된 저전력·저비용 NPU 개발이 필수다.시장조사업체 옴디아에 따르면 글로벌 추론용 AI반도체 시장은 2030년 1430억 달러 규모로 성장할 것으로 예상된다. GPU의 막대한 전력 소비, 운영 비용 등을 감안하면 향후 추론에 특화된 NPU의 중요성은 더욱 커질 전망이다.현재 저전력 국산 NPU가 출시 중이지만 아직 초기 단계다. 정부는 상용화할 수 있는 수준으로 NPU를 고도화하고 이러한 기술력으로 AI컴퓨팅 인프라 자립화 등을 노린다. 또한 국산 NPU를 개발 중인 독자 AI모델과도 연계, 향후 피지컬AI에 특화된 초저전력 미래기술력을 확보할 방침이다.과기정통부 관계자는 &quot;AX, AI 서비스를 구현하는데 GPU만으로는 한계가 있고, 그 한계로 NPU 등 새로운 시장 기회가 생기는 것&quot;이라며 &quot;AI 시장도 분화가 되면서 맞춤형 모델, 맞춤형 AI칩이 계속 나오게 될 것&quot;이라고 말했다.

---

*Crawled at: 2025-12-28 21:46:56*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/421/0008683201)*
