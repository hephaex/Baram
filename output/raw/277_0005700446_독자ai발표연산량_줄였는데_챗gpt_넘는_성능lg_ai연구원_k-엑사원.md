---
id: 277_0005700446
title: "[독자AI발표]연산량 줄였는데 챗GPT 넘는 성능…LG AI연구원 &#x27;K-엑사원&#x27;"
category: 
publisher: 아시아경제
author: 
		
			박유진 기자 genie@asiae.co.kr
		
	
published_at: 2025-12-30 00:00
crawled_at: 2025-12-30 09:49:06
url: https://n.news.naver.com/mnews/article/277/0005700446
oid: 277
aid: 0005700446
content_hash: 6c23d9bcd835a0d4fa987e09f41e161d2aebe4a3ccdb0b4945da231573a8c574
---

# [독자AI발표]연산량 줄였는데 챗GPT 넘는 성능…LG AI연구원 &#x27;K-엑사원&#x27;

**아시아경제** | 2025-12-30 00:00 | 

---

독자 AI 파운데이션 모델 1차 발표회중저가 GPU에서도 구동 가능한 K-엑사원 공개

LG AI연구원은 학습 연산량을 기존 대비 3분의 1 수준으로 낮추면서도 미국의 챗GPT와 중국의 큐웬 등 글로벌 프론티어 모델을 웃도는 성능을 확보한 인공지능(AI) 모델 &#x27;K-엑사원&#x27;을 공개했다.최정규 LG AI연구원 AI에이전트 그룹장은 30일 서울 코엑스에서 열린 과학기술정보통신부 주최 &#x27;독자 AI 파운데이션 모델&#x27; 프로젝트 1차 발표회에서 &quot;성능은 유지하면서도 학습에 필요한 연산량을 기존 대비 약 30% 수준으로 낮췄다&quot;며 &quot;효율적인 구조를 통해 비용 부담을 줄이는 데 초점을 맞췄다&quot;고 말했다.최 그룹장은 기존 대규모 언어모델(LLM)의 한계로 &#x27;연산 비용&#x27;을 꼽았다. 문장 속 모든 단어 간 관계를 계산하는 방식은 성능은 뛰어나지만, 학습과 운영에 많은 비용이 든다는 설명이다. 그는 &quot;모든 정보를 다 계산하지 않아도 필요한 정보만 선택적으로 활용할 수 있다&quot;며 &quot;이를 위해 하이브리드 어텐션 구조를 효율적으로 설계했다&quot;고 설명했다.이 모델은 중저가급 GPU 환경에서도 구동이 가능하다. 최 그룹장은 &quot;고가의 인프라가 아니어도 모델을 운영할 수 있어 초기 구축 비용과 운영 부담이 상대적으로 적다&quot;며 &quot;스타트업이나 중소기업도 바로 활용할 수 있는 AI 모델&quot;이라고 말했다.학습 방식은 단계적으로 구성됐다. 일반적인 기본 지식을 먼저 학습한 뒤, 사고력을 강화하는 학습을 거쳐, 마지막으로 특정 분야의 전문 지식을 학습하는 구조다. 최 그룹장은 &quot;이전 단계에서 쌓은 지식을 바탕으로 다음 단계 성능을 끌어올리는 방식&quot;이라며 &quot;이런 학습 전략을 통해 가용 인프라를 효율적으로 활용할 수 있었다&quot;고 설명했다. 실제 GPU 인프라 활용 효율은 평균 89.4%를 기록했다.성능 평가 결과도 공개됐다. LG AI연구원이 주요 벤치마크 13개 항목을 자체 평가한 결과, 평균 성능은 목표치 대비 104%를 기록했다. 300B(3000억개) 파라미터 이하 모델 기준으로는 오픈AI의 GPT-OSS(120B)와 중국 큐웬3(235B) 등 글로벌 모델과 비교해도 상위권 성능을 확보했다고 설명했다.안전성과 신뢰성도 강조했다. LG AI연구원은 학습 데이터 전반에 대해 컴플라이언스 검토를 진행하고, 문제가 될 소지가 있는 데이터는 다른 데이터로 대체하는 절차를 운영하고 있다. 또 인류 보편적 가치, 사회 안전, 한국적 특수성, 미래 위험 대응 등 여러 영역을 기준으로 모델을 점검하고 있다고 밝혔다.

---

*Crawled at: 2025-12-30 09:49:06*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/277/0005700446)*
