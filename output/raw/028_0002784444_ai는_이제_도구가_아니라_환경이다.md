---
id: 028_0002784444
title: "AI는 이제 도구가 아니라 환경이다"
category: 
publisher: 한겨레
author: 
		
			한겨레 hanidigitalnews@hani.co.kr
		
	
published_at: 2026-01-02 00:00
crawled_at: 2026-01-02 03:18:16
url: https://n.news.naver.com/mnews/article/028/0002784444
oid: 028
aid: 0002784444
content_hash: 21c85db98ccfbcf8de7ad52a409b27e2c69d17eb077f5cb1d387c4ae67bd7c08
---

# AI는 이제 도구가 아니라 환경이다

**한겨레** | 2026-01-02 00:00 | 

---

손현주의 AI 인류학(1) AI 시대의 빛과 그림자

알파고가 이세돌 9단의 바둑돌을 넘어섰을 때 우리는 전율했고, 챗GPT가 유려한 문장으로 논문을 써냈을 때 우리는 당혹스러움을 감추지 못했다. 바야흐로 인공지능(AI)의 시대다. 서점가는 AI가 가져올 장밋빛 특이점이나, 인간이 기계에 종속될 것이라는 디스토피아적 예언들로 넘쳐난다. 하지만 이 거대 담론의 홍수 속에서 정작 기술과 부대끼며 매일을 살아가는 구체적인 사람의 냄새는 맡기 어렵다. 기술의 압도적인 성능에 매혹되어, 그 기술이 딛고 서 있는 인간의 땅을 잊어버린 탓이다.

앞으로 연재할 ‘손현주의 AI 인류학’을 통해 차가운 기술의 표면 아래 숨겨진 뜨겁고, 때로는 고통스러운 인간의 이야기를 시작하려 한다. 이것은 AI의 연산 속도에 대한 보고서가 아니다. 오히려 AI라는 거울에 비친, 우리 삶의 조건과 인간의 자리에 대한 치열한 성찰이다.삶의 조건이 된 기술우리는 흔히 AI를 인간의 지능을 모방하거나 능가하는 똑똑한 도구로 정의한다. 더 빠르고 정확하게 계산하고, 인간의 노동을 효율적으로 대체하는 수단으로만 이해하는 것이다. 그러나 오늘날 AI는 단순한 도구의 지위를 넘어섰다. 그것은 인간이 숨 쉬고, 생각하고, 타인과 관계 맺는 방식 자체를 근본적으로 재구성하는 하나의 거대한 환경(environment)이 되었다. 우리가 무엇을 볼지 결정하는 유튜브의 알고리즘부터, 늦은 밤 고독을 달래주는 챗봇, 그리고 노년의 마지막 곁을 지키는 돌봄 로봇에 이르기까지, AI는 이미 공기처럼 우리의 일상 깊숙이 침투해 있다.이 지점에서 필요한 것이 바로 AI 인류학이다. AI 인류학은 “AI가 무엇을 할 수 있는가”가 아니라, “AI와 함께 살아가는 인간은 어떻게 변하고 있는가”를 묻는다. 나는 이 연재에서 AI를 추상적인 코드로 보지 않고, 광물과 전력, 센서와 서버라는 물질로 바라보는 ‘디지털 신유물론’의 관점을 견지하려 한다. 우리는 더 이상 인터넷에 접속하는 것이 아니라, 데이터의 흐름 속에서 서식한다. 우리의 마음은 스마트폰과 결합하여 확장되었고, 나의 편리한 검색은 지구 반대편의 광산 노동과 긴밀하게 얽혀 있다. 이 연결고리를 확인하는 것이 AI 인류학의 출발점이다.

클라우드는 가볍지만, 현실의 AI는 무겁다클라우드(Cloud)라는 은유는 인공지능이 마치 구름처럼 가볍고 깨끗한 비물질적 존재인 것처럼 인식하게 만든다. 그러나 이 가벼움은 기술적 현실을 가리는 거대한 착시이자 환상이다. 대형언어모델(LLM)이 문장 하나를 생성하기 위해서는 수천개의 그래픽처리장치(GPU)가 동시에 작동하는 대규모 데이터센터가 필요하며, 이 물리적 요새는 막대한 전기와 물을 끊임없이 소비한다.우리가 챗GPT에게 던지는 가벼운 질문 하나는, 실제로는 생수 한 병에 가까운 물을 소모하는 연산 과정과 연결되어 있다. 2027년 전 세계 AI 관련 물 소비량이 최대 66억세제곱미터(㎥), 즉 약 66억톤에 이를 수 있다는 전망은 결코 과장이 아니다. 이는 대형 댐 수십개에 해당하는 물이 데이터센터 냉각과 연산 유지에 투입되는 규모로, 디지털 인프라가 지구 환경에 가하는 물리적 부담이 얼마나 큰지를 단적으로 보여준다.이러한 부담은 이미 현실의 갈등으로 드러나고 있다. 미국 오리건주 더 댈러스(The Dalles)에서는 구글 데이터센터의 막대한 물 사용을 둘러싸고 지역 주민들과의 분쟁이 발생했으며, 이는 친환경 디지털이라는 수사가 자원 경쟁의 현실 앞에서 얼마나 취약한지를 보여주는 사례다. 한국 역시 이 흐름에서 벗어나지 않는다. 축구장 41개 크기에 달하는 네이버 데이터센터 ‘각 세종’이 첨단 친환경 기술을 내세우고 있지만, 그 이면에는 급격히 증가하는 전력 소비라는 구조적 문제가 자리 잡고 있다. AI는 구름 위에 떠 있는 기술이 아니다. 그것은 뜨거워진 지구 위에, 전기와 물이라는 실질적인 자원을 발판 삼아 무겁게 서 있는 물질적 시스템이다.

알고리즘은 투명하지 않다우리는 알고리즘이 인간의 편견을 배제한 중립적인 판관이 되어주길 기대했다. 그러나 현실의 AI는 우리 사회의 혐오와 차별을 그대로 답습하고, 때로는 증폭시키는 비뚤어진 거울에 가깝다. 2020년 챗봇 ‘이루다’가 쏟아낸 소수자 혐오 발언은 AI가 창조한 것이 아니다. 우리 사회의 카카오톡 대화 100억 건 속에 숨어 있던 차별의 언어를 AI가 충실히 재현했을 뿐이다.또한 알고리즘은 자본의 논리에 복무하며 시장을 왜곡한다. 카카오모빌리티가 자사 가맹 택시에 호출을 몰아주기 위해 알고리즘을 조작했다가 271억원의 과징금을 부과받은 사건은, 소비자가 믿었던 배차의 공정성이 사실은 코드로 짜인 조작된 우연이었음을 드러냈다. 이처럼 AI 인류학은 코드를 단순한 명령어가 아니라, 권력이 작동하고 배제가 일어나는 정치적 텍스트로 읽어낸다.AI는 스스로 똑똑해지지 않는다AI가 스스로 학습한다는 말은 반만 맞다. 이른바 기계 학습이 작동하기 위해서는, 수많은 인간 노동자가 데이터에 라벨을 붙이고 정답을 교정하는 유령 노동(Ghost Work)을 수행해야 한다. 인류학자 메리 그레이(Mary Gray)가 ‘고스트 워크’(2019)에서 지적했듯, 완전한 자동화처럼 보이는 기술의 이면에는 언제나 인간의 손길이 필요하다.한국의 대표적인 데이터 라벨링 플랫폼 ‘크라우드웍스’에는 수십만 명의 작업자가 등록돼 있다. 이들은 AI가 이미지를 인식할 수 있도록 사진 속 사물에 박스를 치거나, 텍스트의 미묘한 뉘앙스를 분류하는 작업을 수행한다. 이 노동은 원하는 시간에 자유롭게 일하는 부업으로 포장되지만, 실상은 건당 몇십원의 저임금과 고용 불안, 그리고 알고리즘에 의한 철저한 통제 속에 놓여 있다. 최근에는 일부 북한 IT 인력이 신분을 위장해 이러한 원격 노동 시장에 유입되었다는 보도까지 나오면서, AI 노동 시장은 지정학적 리스크와 윤리적 딜레마가 복잡하게 얽힌 공간이 되고 있다. 매끄럽고 화려한 AI 서비스의 뒤편에는 이처럼 지워진 얼굴들의 땀방울이 존재한다.

돌봄은 계산될 수 있는가마지막으로 우리가 살펴볼 지점은 AI가 파고든 인간의 내면, 바로 외로움이다. 초고령 사회로 진입한 한국에서, 고독사 사망자 수는 매년 증가하고 있다. 가족과 공동체의 돌봄 기능이 붕괴한 자리를 메우기 위해 정부와 지자체는 ‘효돌’과 같은 AI 돌봄 로봇을 대안으로 내세운다.독거노인에게 약 복용 시간을 알려주고, “할머니 사랑해요”라며 애교를 부리는 로봇을 보자. 많은 노인이 이 기계를 단순한 로봇이 아닌 손자처럼 대하며 정서적 유대감을 형성한다. 그러나 셰리 터클(Sherry Turkle) 교수는 ‘외로워지는 사람들’(2016)에서 “우리는 기술에서 더 많은 것을 기대하고, 서로에게는 점점 덜 기대하게 되었다”라고 지적한다. AI가 제공하는 돌봄은 분명 편리하고 효율적이다. 하지만 알고리즘에 따라 작동하는 반응이 인간이 인간에게 건네는 체온과 눈 맞춤을 온전히 대신할 수 있을까. 혹시 우리는 돌봄이라는 사회적 책임을 기술에 외주화함으로써, 진정한 관계의 의미 자체를 축소하고 있는 것은 아닐까. AI 인류학은 외로움이 어떻게 시장화되고, 인간의 감정이 어떻게 데이터로 환원되는지를 뼈아프게 질문한다.공존의 지혜: 기술 사회를 위한 상상력한국 사회는 세계 최고 수준의 디지털 인프라를 갖추고 있지만, 동시에 초고령화, 양극화, 고립이라는 난제에 직면해 있다. 이런 척박한 토양 위에서 AI는 단순한 기술적 선택지를 넘어 이미 우리의 일상을 떠받치는 조건이 되었다. 그렇기에 한국에서의 AI 인류학적 탐구는 더욱 절실하다.우리는 이제 스스로에게 물어야 한다. 효율성을 위해 우리는 무엇을 기꺼이 포기하고 있는가. 편리함이라는 이름 아래 가려진 환경파괴와 노동 착취, 그리고 차별의 구조를 어떻게 책임질 것인가. 기술은 정해진 운명이 아니다. 결국 선택의 문제다. 어떤 삶을 지키기 위해 어떤 기술을 받아들이고, 어떤 기술 앞에서는 멈춰 설 것인가. AI의 미래가 디스토피아가 되지 않으려면, 우리는 더 빠른 기술이 아니라 더 느린 책임을 선택할 용기가 필요하다.손현주/전주대 창업경영금융학과 교수(미래학)

---

*Crawled at: 2026-01-02 03:18:16*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/028/0002784444)*
