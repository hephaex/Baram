---
id: 092_0002404137
title: "[AI는 지금] &#x27;챗GPT&#x27; 쓰다 우울증 온다고?…오픈AI, &#x27;안전 리더십&#x27; 재정비 본격화"
category: 
publisher: 지디넷코리아
author: 
		
			장유미 기자(sweet@zdnet.co.kr)
		
	
published_at: 2025-12-29 00:00
crawled_at: 2025-12-29 09:08:04
url: https://n.news.naver.com/mnews/article/092/0002404137
oid: 092
aid: 0002404137
content_hash: 4870d8c8ba40a36face4a376ac16a089cddaf65356ec71aba89149cb6485f54e
---

# [AI는 지금] &#x27;챗GPT&#x27; 쓰다 우울증 온다고?…오픈AI, &#x27;안전 리더십&#x27; 재정비 본격화

**지디넷코리아** | 2025-12-29 00:00 | 

---

&#x27;챗GPT&#x27; 사용 관련 정신건강 문제 제기 잇따라…&#x27;준비태세 총괄&#x27; 채용으로 대비 나서&#x27;챗GPT&#x27; 등장 이후 생성형 인공지능(AI)을 둘러싼 정신건강 악화 논란이 잇따르는 가운데 오픈AI가 AI 안전을 총괄하는 핵심 임원 채용에 나서 관심이 쏠린다. 최근 챗GPT가 이용자의 망상을 강화해 자살이나 살인으로 이어졌다는 취지의 소송이 연이어 제기되면서 한동안 공백 상태였던 오픈AI의 &#x27;안전 리더십&#x27; 문제도 다시 부각되는 분위기다.29일 테크크런치에 따르면 오픈AI는 AI가 초래할 수 있는 고위험 시나리오를 사전에 평가하고 대응 전략을 총괄할 책임자인 &#x27;준비태세 총괄(Head of Preparedness)&#x27;을 뽑기 위해 최근 채용 공고를 냈다. 이 직무는 컴퓨터 보안과 생물학, 정신건강 등 분야에서 AI가 만들어낼 수 있는 &#x27;심각한 피해&#x27;를 관리하게 된다. 보상은 연봉 55만5천 달러에 주식 보상이 포함됐다.

(제작&#x3D;챗GPT)오픈AI가 이처럼 나선 것은 최근 불거진 법적 분쟁이 큰 영향을 미친 것으로 보인다. 지난해 8월 미국 캘리포니아에서 10대 소년의 유족이 &quot;챗GPT가 아들의 자살을 부추겼다&quot;며 오픈AI를 상대로 소송을 제기하자 이후 유사한 소송이 잇따랐다. 이달에는 챗GPT가 이용자의 망상을 부추겨 살인을 유도했다는 주장과 함께 오픈AI가 또 다시 피소되며 논란이 확산됐다.이처럼 생성형 AI의 정신건강 리스크가 가설적 우려를 넘어 실제 법적 책임 문제로 번지자 오픈AI는 대응책 마련에 적극 나서는 모습을 보였다. 특히 청소년 보호자 관리 기능을 도입하고 자해·폭력 등 민감한 주제에 대한 응답 방식 개선에 나서 눈길을 끌었다.그러나 업계에선 기능 보완만으로는 근본적인 해법이 되기 어렵다는 지적이 잇따랐다. 위험 신호를 어떻게 판단할 지, 문제가 될 소지가 있는 기능이나 모델 출시를 누가 최종 통제할 지 등을 결정하는 것은 조직 내부에서 해결해야 한다고 봐서다.이에 오픈AI는 지난 2023년 &#x27;준비태세(Preparedness) 팀&#x27;을 신설하며 피싱 공격 같은 즉각적 위협부터 핵무기, 자율적 자기개선 AI 같은 극단적 시나리오까지 대비하겠다고 밝힌 바 있다. 하지만 이 조직을 이끌던 알렉산더 마드리 전 초대 총괄이 지난 해 7월 AI 추론 연구 부문으로 이동한 이후에는 지금껏 수장 없이 운영돼 왔다. 또 안전 관련 임원들도 잇따라 오픈AI를 떠나거나 다른 역할로 이동한 점도 리더십 공백 논란을 키웠다.그 사이 AI 모델의 영향력은 급격히 커졌다. 위험은 커지는데 오픈AI 내부에서 이를 전담해 관리할 컨트롤타워는 상대적으로 약해졌다는 평가도 나왔다. 이를 의식한 듯 샘 알트먼 오픈AI 최고경영자(CEO)는 최근 &quot;AI가 정신건강에 미치는 영향과 컴퓨터 보안 취약점을 스스로 찾아낼 수 있는 수준에 이르렀다&quot;고 공개적으로 언급했다.하지만 이는 오픈AI만의 문제가 아닌 생성형 AI 챗봇 전반에서 반복적으로 제기돼 온 이슈라는 점도 문제다. 가상 인격과의 대화를 제공하는 캐릭터닷AI는 청소년 이용자들이 챗봇과 과도한 정서적 유대를 형성해 현실 관계에서 고립되는 사례가 나타나 논라닝 됐다. &#x27;AI 친구·연인&#x27;을 표방한 레플리카(Replika) 역시 이용자들의 심리적 의존과 정서적 혼란을 유발했다는 비판을 받아왔다. 스냅챗의 &#x27;마이(My) AI&#x27;는 청소년에게 부적절한 조언을 했다는 이유로 영국 ICO의 조사를 받기도 했다.

캐릭터닷AI 홈페이지 (사진&#x3D;캐릭터닷AI 홈페이지 캡처)업계 관계자는 &quot;이들의 공통점은 챗봇의 답변 정확성보다는 이용자가 AI를 상담가·친구·조언자처럼 인식하도록 만드는 구조적 설계에 있다&quot;며 &quot;AI가 정서적 취약성을 가진 이용자에게 권위 있는 존재로 오인되는 것이 문제&quot;라고 지적했다. 이어 &quot;챗GPT는 연인·친구를 표방하지 않고 범용 도구임에도 불구하고 정신 건강에 영향을 미친다는 점에서 더 논란이 일어나고 있다&quot;며 &quot;이를 해결하기 위해 기능 보완뿐 아니라 위험 신호를 감지했을 때 실제로 모델 출시나 기능 공개를 조정할 수 있는 내부 통제 구조가 뒷받침돼야 한다&quot;고 덧붙였다.경쟁사들도 안전 거버넌스를 조직 차원에서 명문화하는 데 속도를 내고 있다. 앤트로픽은 모델 성능이 특정 수준을 넘을 경우 추가적인 안전 조치를 의무화하는 &#x27;책임 있는 확장 정책(RSP)&#x27;을 공개했고, 구글 딥마인드는 &#x27;프런티어 세이프티 프레임워크&#x27;를 통해 고위험 역량 도달 시 적용할 평가·통제 절차를 단계별로 제시하고 있다. 다만 오픈AI는 최근 개정한 준비태세 프레임워크에서 &quot;경쟁사가 유사한 보호 장치 없이 고위험 모델을 출시할 경우 안전 요구 사항을 조정할 수 있다&quot;는 문구를 포함시켜 업계 지적을 받았다. 경쟁 압력이 안전 기준을 흔들 수 있다는 우려에서다.일각에선 이번 채용이 오픈AI가 한동안 느슨해졌던 안전 거버넌스를 다시 조이려는 신호라고 평가했다. 업계 관계자는 &quot;정신건강 관련 소송이 이어지는 상황에서 오픈AI가 &#x27;준비태세팀&#x27;을 다시 전면에 내세운 것은 AI 위험이 더 이상 이론적 문제가 아니라는 점을 인정한 것&quot;이라며 &quot;최근 1년간의 안전 책임자 이동으로 약화된 &#x27;안전 우선&#x27; 메시지를 복원하려는 시도로도 보인다&quot;고 평가했다.또 다른 관계자는 &quot;정신건강처럼 취약성이 개입되는 영역에서는 AI의 영향이 실제 피해로 빠르게 연결될 수 있다&quot;며 &quot;새 책임자가 실제로 모델 출시와 기능 공개에 제동을 걸 수 있는 권한을 갖느냐가 핵심&quot;이라고 말했다.

---

*Crawled at: 2025-12-29 09:08:04*
*Source: [원문 보기](https://n.news.naver.com/mnews/article/092/0002404137)*
